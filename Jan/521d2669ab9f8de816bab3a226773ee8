Site moderators say they are forced to check up to 1,700 videos a day for explicit content, adding they often watch four films ­simultaneously to meet their targets. The workers, who insisted on speaking anonymously for fear of losing their jobs, said they “inevitably missed” dangerous content, as they had to squeeze 40 hours of viewing into an eight-hour shift. The moderators told Revealing Reality, a research group that works with Ofcom, that the “volume of content they were expected to get through each day was unmanageable” and raised questions over the platforms’ commitment to removing dangerous films. All said they had seen videos showing murder, suicide, accidental death, porn, kidnapping, and animal cruelty. One moderator said: “I saw people hanging themselves. I saw a girl shooting her head off.” Another said: “People just want to get viral and they want to get views. So it’s disgusting. People want to be noticed. "So they’re willing to do anything just to have views, just so that people can share their content.” Some moderators said they were told not to “overkill” content that was proving popular with users, meaning “questionable” material remained online. The disclosures come with the Online Safety Bill, which aims to protect children from harmful content, still progressing through Parliament.