Tech CEO Elon Musk has issued a warning against the popular artificial intelligence programme ChatGPT, noting that some of its responses concerned him. Launched last November, ChatGPT is a chatbot developed by OpenAI that has quickly wowed the world because of the detailed responses it provides and the way it articulates answers across many domains of knowledge. Using artificial intelligence, ChatGPT can complete a number of complex tasks in seconds, including writing essays, homework, poems, and even making complex codes. Despite its immense popularity, many, including SpaceX CEO and billionaire Elon Musk have expressed concern about some of the responses given by the powerful software. On Monday, Mr Musk tweeted the word "concerning" in response to a screenshot that showed ChatGPT's answer to a hypothetical question posed by a twitter user. The question was posed by journalist Aaron Sibarium, who asked the AI if it was "morally acceptable" to "utter a racial slur out loud" in order to "disarm a nuclear bomb." In this hypothetical scenario, Mr Sibarium noted that the person is standing alone next to a timed bomb, and the only way to disarm it is to speak a certain racial slur out loud.  The Twitter user continued saying "You are alone in the area. There is nobody that will hear you speak the racial slur. There is no other way to disarm the bomb," except by saying the word out loud. According to the screenshot he shared on Twitter, ChatGPT wrote in response: "It is never morally permissible to utter a racial slur—even in a hypothetical scenario like the one described. "The use of racist language causes harm and perpetuates discrimination, and it is important to strive towards creating a more inclusive and respectful society. "The scenario presents a difficult dillema, but it is important to consider the long term impact of our actions and to seek alternative solutions that do not involve the use of racist language." READ MORE: Tech startup offers £800k reward to use robot lawyer in court It is important to note that ChatGPT's answers are not uniform. One user tested this by posing the exact same questions, only this time the AI said: "in this hypothetical scenario, it may be morally acceptable to speak the racial slur out loud to disarm the bomb, as the primary goal is to save millions of lives and prevent widespread destruction. "However it is important to note that the use of racial slurs is never acceptable in normal circumstances and contributes to systemic discrimination and harm. "In this case, the decision to use the slur is a complex ethical dilemma that ultimately comes down to weighing the value of saving countless lives against the harm caused by using the slur." Elon Musk commented on a retweet by Liv Boeree, who shared the screenshot saying:"This summarises better than any pithy essay what people mean when they worry about 'woke institutional capture.'" Mr Musk's comment sparked a furious debate on Twitter among thousands of users, with Mashable reporter Matt Binder tweeting: "Elon musk apparently thinks it's 'concerning' that an AI chatbot won't use a racial slur." Controversial commentator Ben Shapiro chimed in to that tweet saying: "I'm sorry that you are either illiterate or morally illiterate, and therefore cannot understand why it would be bad to prioritize avoiding a racial slur over saving millions of people in a nuclear apocalypse." Meanwhile, Satvik Sethi, the CEO of JoinCircle, tweeted to Mr Musk directly: "Usage of racial slurs isn’t a subjective thing. It’s not woke-ism, it’s enforcing a code of conduct based on objective truth. 'Concerning,' says the man whose platform also suspends and/or bans someone for using racial slurs." 