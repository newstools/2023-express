A British tech start-up company has vowed to tackle the abuse of its voice-cloning equipment after Sir David Attenborough’s voice was also used in a racist recording. The audios were posted on message board 4Chan after users abused the voice-cloning technology in the latest misuse of AI. Technology released by ElevenLabs, a research company, allows users to use the text-to-audio tool to type in words and hear them repeated in a human voice. The company was founded by two former Google and Palantir engineers who also created voice cloning and dubbing abilities for film and publishing industries. The technology has been abused by some users who have taken the voice-cloning tool to create a deepfake from a recording as small as one minute long. President Biden was also targeted in the misuse with a recording of the President making sexist and transphobic comments. In a recent announcement, ElevenLabs founders Mati Staniszewski and Piotr Dabkowski declared that they received funding of £1.6million. Such “generative AI” technologies are taking the sector by storm and have been praised with the capability to revolutionise the creative industries and other businesses. However, the new technology has proven to come with great benefits but large risks as AI companies find themselves stuck in what has been called an “open-ness dilemma”. The tech research start-up has since vowed to implement defences against such abuse of its products. READ MORE: China lashes out on ‘unscrupulous’ US after crackdown on Huawei It tweeted: “Thank you to everyone for trying out our Beta platform. While we see our tech being overwhelmingly applied to positive use, we also see an increasing number of voice-cloning misuse cases.” Such issues faced by ElevenLabs saw Microsoft’s artificial intelligence programme VALL-E closed off to the public. The software can duplicate a voice from a three-second audio clip but the company cited ethical issues as a reason not to make it available to the general public. Microsoft added that misuse included “spoofing voice identification or impersonating a specific speaker”. Meanwhile, ElevenLabs noted that it has idenitified that “speaking in somebody else’s voice raises ethical concerns since it can be used for nefarious purposes”. DON'T MISS:Seventh Nichols cop 'relieved of duty' and three fire staff sacked (INSIGHT)US general warns British Army no longer top-level fighting force (REVEAL)Meghan's after-school ritual teaches Archie heartwarming life lesson (INSIGHT) The tech start-up has been accused by deepfakes expert Henry Ajder of being “fairly naïve”. He said: “What they have developed, technologically, is very impressive [but] by opening up these models they have made, unfortunately, a fairly naïve judgement about the intentions of those people out there who will use those models. “In this climate of hype cycle around generative AI, a lot of companies are rushing and trying very hard to stand out from a very noisy scene. “I worry that the kind of feverish rush is perhaps leading certain organisations to cut corners when it comes to safety considerations, although I’m not saying that’s necessarily what motivated Eleven in this case.”