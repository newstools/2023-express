Deepfake videos are seen more and more on people’s social media feeds as well as the darker areas of the internet. Research has shown that searches for “deepfake porn” have increased by a staggering 1,000 percent in January alone. Spotting the signs of artificial intelligence is now vital. Read our expert tips and then take our quiz to see whether you can tell the deepfake from the real deal. Realistic fake videos or “deepfake” videos and images took the internet by storm in 2017, although the technology was discovered 20 years before. “Deepfake”, a term referencing the artificial intelligence technology called “deep learning”, are videos or images made using artificial intelligence to create convincing photos or images from scratch. In 1997, Christoph Bregler, Michele Covell, and Malcolm Slaney designed a program that altered video footage to create a new video of someone mouthing words they did not originally say. Then in 2017, a social media user uploaded artificial intelligence onto the platform Reddit, which enabled others to make their own deepfake videos.  A staggering 96 percent of deepfake videos are pornography, according to the BBC, with hundreds of deepfake videos making their way onto pornographic websites every month. Sensity, a deepfake detection company, found that in 2020 around 1,000 deepfake videos were uploaded to pornographic sites each month. These videos often use celebrities’ faces — a deepfake of Harry Potter star Emma Watson had been viewed some 23 million times. But famous faces are not the sole targets of image-based sexual abuse. One woman told the BBC that she was made into a deepfake by a colleague. Deepfakes have also made their way into politics and are now being utilised by scammers. In 2020, two videos of Manoj Tiwari, President of Bharatiya Janata Party, went viral on Whatsapp — reaching some 15 million people — to dissuade voters from siding with the rival political party. In 2021, parliamentarians from the UK, Estonia, Latvia, and Lithuania arranged a video call with a hoaxer who pretended to be Leonid Volkov, Alexei Navalny’s chief of staff. Just last year, a video of Elon Musk promoting a crypto scam surfaced which later turned out to be a deepfake. Nicholas Crouch, from Scams.info, told Express.co.uk: “This can be dangerous as the subjects being used are usually influential people, which makes them seem more trustworthy to members of the public. “Victims will often trust the deepfake subject and give the scammer personal details such as credit card information and addresses which can scam them out of millions of pounds. It's therefore important to understand the dangers of deepfake technology and how to spot it, to ensure you don’t fall for it in the future.” READ MORE: Three experts' wildly different predictions for future of Ukraine war In short, no, not yet. While it is highly unlikely deepfake would be banned outright, the Online Safety Bill is now due to be amended to make it illegal to share a pornographic deepfake online. Although the videos themselves are legal, a victim of a pornographic face swap could make claims of defamation or copyright, for example. The experts at Scams.info shared their tips with Express.co.uk on how to spot a deepfake. 1. Facial imperfections Look closely for imperfections or blurred image quality such as around the hairline, which will show you that you are not looking at or talking to who you think you are. On streaming services like YouTube you slow down or speed up the videos which will help imperfections appear more obvious. 2. Rapid eye movement One of the most common signs that a video has been deepfaked is the lack of movement in the person's eyes. Typically, there is a rigidity to the motion of the eyes and a lack of blinking. This is one of the easiest signs to pick up on as the average person blinks 15-20 times each minute. DON'T MISS:Beatles 'embarrassed' by huge hit Hard Day's Night [REPORT]Master ‘manipulator’ Putin makes others feel like his ‘best friend’ [INSIGHT]POLL – Should Prince Andrew be evicted from Windsor estate? [POLL]  3. Side profile A recurring flaw with the software that generates a deepfake is that it is limited to analysing 2D features of the face. This means that when displaying a person’s side profile, the technology will be more likely to create a generic-looking facial profile. 4. Audio quality Listen to the audio quality carefully to see if you can detect any differences in how the person in question usually talks, like their phrasing, accent, and tone. As seen in the recent Musk deepfake, the voice was relatively believable. Still, a handful of words were pronounced in a way that isn't uniform to his accent, words being abruptly cut short and giving the likeness of a robot. 5. Colour contrasts A simple sign that a video is a deepfake, is the lighting and colouring of the video. When casting a new face on top of an existing figure, it will bring with it the lighting and shadows from the original images that will struggle to match the new environment it is been placed into. Not only will there be a discrepancy here, but any new shadows and lighting within the video won't be cast onto the face as it’s an addition after the video has already been taken. Now test your knowledge with the quiz below (if you're unable to see it, head here).