Fraudsters are tricking victims into sending them cash by mimicking the voices of loved ones with AI technology that makes them sound "eerily" similar to friends and family. AI has made it easier for scammers to swindle unsuspecting members of the public - often the vulnerable and the elderly. Ruth Card, 73, thought she was getting a phone call from her grandson, Brandon when she was almost tricked into handing thousands to a scammer at the other end of the phone. The caller, posing as her grandson, claimed he needed bail money and didn't have access to his own funds. Ms Card, of Regina, Saskatchewan, told The Washington Post: "It was definitely this feeling of … fear. That we’ve got to help him right now." The gran rushed to a nearby bank and withdrew $2,207 (£1,840), and then went to another bank to withdraw more. But luckily she was stopped by the bank's manager, who told her another customer had received a similar call, confirming that the phone scammer wasn't their grandson. Experts warn artificial intelligence is making it easier for scammers to trick victims into thinking they are helping out a loved one. The US Federal Trade Commission reported that imposter scams were the second most popular con in the US, with over 36,000 reported cases in 2022. READ MORE: Woman risks losing her home after she waved cyclist into fatal crash The CEO of an unnamed UK company transferred $243,000 (£202,394) to pay someone he believed to be a Hungarian supplier because he thought he was on the phone with his supervisor from the German headquarters of the business. But it was a deepfake voice created by an AI scam. A similar incident happened in 2021 when a Hong Kong bank manager was allegedly tricked by a voice cloning scam, when he believed the company's director had asked him to authorise a transfer of $35 million, Forbes reported. Don't miss... Santander warning after customer receives suspicious letter [LATEST] Santander warning as Britons victimised by social media fraudsters [VIDEO] Woman loses £23,000 after mysterious £30 payment lands in her bank [COMMENT] Impostor scams can be carried out in many different ways but essentially they all dupe the victim into believing the scammer is someone trustworthy — a child, lover or friend — and convinces the victim to send them money. Voice-replicating AI uses technology to analyse what makes a person's voice unique and searches a database to find similar voices, Hany Farid, a professor of digital forensics at the University of California told the Post. Express.co.uk has contacted the National Crime Agency for further comment and information. Follow our social media accounts here on facebook.com/ExpressUSNews and @expressusnews