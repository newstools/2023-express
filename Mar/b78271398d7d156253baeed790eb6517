ChatGPT is a new Artificial Intelligence (AI) natural language processing tool that essentially generates human-like text based on the inputs you give it in a matter of seconds. Made by San Fransisco-based firm OpenAI and recently bought by Microsoft, it can generate a vast array of content. For instance, it can bash out an essay for a student in seconds, or help a computer programmer debug code. But while the technology has a range of uses, it has also raised concerns. According to Toby Lewis, Global Head of Threat Analysis at Darktrace, the fact that it is widely available throws up risks for anyone using the internet. He told Express.co.uk: “These technologies aren’t super Government weapons. They’re on google. Microsoft has just bought ChatGPT. This platform and tooling is freely available for members of the public to play around with.” He warned that the technology could help online fraudsters pick up the pace of their scams and attacks. Mr Lewis explained: “Really at its core, most AI can’t really do anything that does not already exist nor that a human cannot already do. It is very much around accelerating the ability to generate some of this content. “AI more generally is really about trying to increase the effectiveness of humans by allowing them to deliver something much faster. “With ChatGPT, the responses that you get and how it is able to craft messages that look really realistic…could a human generate some of that material? Yes, but they would have to work really hard and know the language, the nuances and the technology, but it could be really easy for them to slip up and make a mistake. “What AI and ChatGPT allows them to do is really accelerate some of that learning in terms of that ability to take on this new skill, this new role, without some of the skills-gather learning requirements that go with it.” He warned that this could mean cyber fraudsters have a higher success rate in their efforts to obtain your private information. READ MORE: BT warns users of shock broadband change this month, are you affected? Mr Lewis added: “It reduces that barrier for entry and there is a chance that it makes it more successful. “That ability to manipulate people becomes more effective and more polished without all the extra requirements of native speakers, without someone having to spend time crafting a message, it is a really interesting step forward for attackers that is now really widely available.” Since the online tool has blown up, reports have emerged that hackers have been using ChatGP for a number of different scams on the web. For instance, dating scammers have created chatbots designed to impersonate young females to lure in targets, using the tool to create conniving personas. Experts have also warned that ChatGPT could be used to help scammers build websites and bots that trick users into sharing their information. This could include “the creation and personalisation of malicious web pages, highly-targeted phishing campaigns and social engineering reliant scams.” Forescout vice President Rik Ferguson told Forbes in an interview. However, while it is a powerful tool, Mr Lewis noted that it still has its flaws that could limit its effectiveness for the time being. He said: “You are feeding data into it that it learns the behaviour of, it learns what normal looks like for that data set. But it only knows the data you feed into it. It is very much focused around that information and that is one of its pitfalls.”